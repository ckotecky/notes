2022-10-25
lecture #3
----------



Df: Absorption state
--------------------
- state `S: p{s,s} = 1`


Ex: Absorption probability
--------------------------
- fly and spider in corridor
- end states are **absorption states**
- `P[fly ends up at 0 | fly starts at i] = ai = P[‚àÉt: Xt = 0 | X0 = i]`
	+ `a0 = 1`
	+ `a3 = 0`
	- `a1 = 0.3 * 1 + 0.4 * a1 + 0.3 * a2`
		+ `P[‚àÉ 0 | 1] = P[X1 = 0 | X0 = 1] * 1 + P[X1 = 1 | X0 = 1] * P[‚àÉ0 | 1] + ...`
	- `a2 = 0.3 * a1 + 0.4 * a2 + 0.3 * 0`
		+ `0.6 * a2 = 0.3 * a1`
		+ `a1 = 2 * a2`
		+ `2 * a2 = 0.3 + 0.8 * a3 + 0.3 * a2`
		+ `0.9 * a2 = 0.3`
		+ `a2 = 1/3`
		+ `a1 = 2/3`


Th: Absorption probability
--------------------------
1. assume a Markov chain with absorbing state 0 (& some more)
	- `‚àÄi ‚àà S: ai := P[‚àÉt: Xt = 0 | X0 = i]`
2. `(ai)` are the unique solution to:
	- `a0 = 1`
	- `ai = \{`
		+ `0 					 	i ‚â† 0` but is absorbing
		+ `ai = Œ£{j ‚àà S} p{ij} * aj	i` not absorbing
			
### Proof:
- `a0 = 1`
	+ easy
- `ai = 0`   if i ‚â† 0 and i is not absorbing
	+ easy
- `ai = P[‚àÉt: Xt = 0 | X0 = i]`
	+ by total probability (conditional version) = `Œ£{j ‚àà S} P[X1 = j | X0 = i] * P[‚àÉt: Xt = 0 | X0 = i, X1 = j]`
		* `P[X1 = j | X0 = i] = p{ij}`
		* by Markov property `P[‚àÉt: Xt = 0 | X0 = i, X1 = j] = P[‚àÉt: Xt = 0 | X1 = j]`
		* `P[‚àÉt: Xt = 0 | X1 = j] = P[‚àÉt: Xt = 0 | X0 = j] = aj`
- this shows that `a0, a1, ...` satisfy equations
- uniqueness omitted (might be in lecture notes)



Th: Conditional total probability
---------------------------------
1. `P[A] = Œ£i P[Bi] * P[A | Bi]` 						simple version
2. `P[A | B] = Œ£i P[Bi | C] * P[A | Bi ‚àß C]` 			conditional version
	- new probability space `Œ©' = C: P'[S] = P[S | C]`


Df: Mean time to absorption
---------------------------
1. `A ‚äÜ S` 						set of all absorbing states
2. `T = min{t ‚â• 0: Xt ‚àà A}` 	random variable, **absorption time**
3. `Œºi = ùîº[T | X0 = i]` 		**mean absorption time**


Th:
---
- `(Œºi){i ‚àà S}`  is the unique solution to:
1. `i ‚àà A  	Œºi = 0`
2. `i ‚àâ A 	Œºi = 1 + Œ£{j ‚àà S} p{ij} * Œºj`


Ex:
---
- `Œº0 = Œº3 = 0`
- `Œº1 = 1 + 0.3 * 0 + 0.4 * Œº1 + 0.3 * Œº2`
- `Œº2 = 1 + 0.3 * Œº1 + 0.3 * Œº2 + 0.3 * 0`
	+ `Œº1 = Œº2 = x`
	+ `x = 1 + 0.7 * x`
	+ `x = 10/3`


Ex:
---
- Markov chain:
	+ states `{0, ..., n}`
	+ `p{n,n} = 1`
	+ `p{0,1} = 1`
	+ `p{n,n-1} = 0`
	+ all others are `1/2`
- `A = {n}`
1. `Œºn = 0`
2. `Œºk = 1 + (Œº{k-1} + Œº{k+2})/2` 		for `0 < k < n`
	+ `Œº1 = 1 + (Œº0 + Œº2)/2`
	+ `2 * Œº1 = 2 + (1 + Œº1) + Œº2`
	+ `Œº1 = 3 + Œº2`
	+ `2 * Œº2 = 2 + Œº1 + Œº3 = 2 + 3 + Œº2 + Œº3`
	+ `Œº2 = 5 + Œº3`
3. `Œº0 = 1 + Œº1`
	+ `Œº0 = 1 + Œº1 = t`
	+ `Œºk = t - k^2 = n^2 - k^2`
+ verification: `n^2 - k^2 = 1 + (n^2 - (k-1)^2 + n^2 - (k+1)^2)/2`



Ob:
---
1. `‚àÄk: Œºk ‚â§ n^2`
2. 
	- `Œºn = 0`
	- `Œº{n-1} = n^2 - (n-1)^2 = 2n - 1`
	

Ex: SAT
-------
- is a given Boolean formula satisfiable?
1. 2-SAT
	+ `œÜ = (x1 ‚à® x2) ‚àß (x3 ‚à® x4) ‚àß ...`
	+ `n` variables
	+ conjunction of clauses
	+ each clause has ‚â§ 2 literals
	- linear (polynomial) solution
2. 3-SAT
	- hard
	

Alg: 2-SAT
----------
- `m` arbitrary paramter
1. Start with any assignment 	`(x1 = x2 = ... = xn = F)`
2. Repeat up to `2mn^2` - times:
3. 		If `œÜ` is satisfied:
4.   		Return variables `x1, ..., xn`
5.      Otherwise choose any unsatisfied clause
6.      Change its random variable
7. We say `œÜ` is unsatisfiable

### Proof:
1. if we find a solution, it is correct
2. suppose `œÜ` is satisfiable
	- `œÜ(s1, ..., sn)` is true
	- random variable `Xt = |{i: Xi = si at time t}| ‚àà [n]0`
	- if `Xt = n  =>`  we are done
	- if `Xt = 0  =>  X{t+1} = 1`
	- if `0 < Xt < n  =>  `
		+ `(x1 ‚à® x2)` not satisfied
		+ `x1 ‚â† s1`  or  `x2 ‚â† s2`  (or both)
		+ suppose `x1 ‚â† s1`
			* if we switch `x1  =>  X{t+1} = Xt + 1`
			* if we switch `x2  =>  X{t+1} = Xt +/- 1`
			* this is not a Markov chain
		+ we assign `Y{t+1} = Yt + 1` with `p = 1/2` or `Y{t+1} = Yt - 1` with `p = 1/2`
			* this is a Markov chain
			* `Œºk = n^2 - k^2 ‚â§ n^2`
			

Analysis
--------
1.
 	- `T` : 	time to reach `Xt = n`
 	- `ùîº[T] ‚â§ n^2`
 	- `P[T ‚â• 2mn^2] ‚â§ 1/2m`
 		+ by Markov inequality
 		+ `2mn^2 = 2m * ùîº[T]`
 	- `P[incorrectly saying no] ‚â§ 1/2m`
2.
	- split the time into m parts of `2n^2` steps
	- `P[we don't find a solution in first 2n^2 steps] = P[T > 2n^2] ‚â§ 1/2`
		+ by Markov inequality
	- `P[we don't find a solution in the second 2n^2 steps] ‚â§ 1/2`
	- `P[incorrectly saying no] ‚â§ (1/2)^m`


Alg: 3-SAT
----------
- `(x1 ‚à® x2 ‚à® x3) ‚àß ...`
1. try the same algorithm
	+ probability of increasing number of good solutions is `1/3`
	+ probability of decreasing number of good solutions is `2/3`
	+ now `Œº0 = Œò(2^n)`
2. one possible improvement
	+ `P[X{n/2} = n | X0 ‚â• n/2] ‚â• 3^{-n/2}`
	+ starting at state `k ‚â• n/2`
		* we always go right by chance with the probability `(1/3)^{n/2}`
		* divide the total time into blocks of `n/2` steps
		* at each step we generate `x1, ..., xn` by random
		* then ``X0 ~ Bin(n, 1/2)``
		* `P[sucess in one part] ‚â• P[X0 ‚â• n/2] * P[X{n/2} = n | X0 ‚â• n/2] ‚â• 1/2 3^{-n/2}`
		
		- lesson finished, to be continued (clarified)