2022-10-11
lecture #2
----------


- no lecture and tutorial next week



`P[X1 = 1, X2 = 2, X3 = 1  ∧  X4 = 0 | X0 = 1] = P[X1 = 1 | X0 = 1] * P[X2 = 2 | X1 = 1] * P[X3 = 1 | X2 = 2] * P[X4 = 0 | X3 = 1] = p11 * p12 * p21 * p10`
- chain rule + markov chain definition


Df: Irreducible Markov chain
----------------------------
- a Markov chain is **irreducible** if `<->` has just one equivalence class
- `∀i,j: i <-> j`


Ob: Irreducible Markov chain
----------------------------
- each class is a strongly connected digraph
- collapsing classes into single events produces a DAG


Df: Recurrent state
-------------------
1. `i ∈ S` is **recurrent**, if `∀j ∈ A(i): i ∈ A(j)`
	+ there are no single way exits that don't return  -  incorrect?
2. otherwise it it **transient**

- finite MC must be recurrent?


Df: Probability of returning
----------------------------
- `i ∈ S: f_{ii} = P[∃t ≥ 1: Xt = i | X0 = i]`


Th: Recurrent & transient states
--------------------------------
1. i is **recurrent**   `<=>   f{ii} = 1`
2. i is **transient**   `<=>   f{ii} < 1`

### Proof:
- `i` is transient  `=>  ∃j ∈ A(i): i ∉ A(j)`
- starting with `X0 = i  =>  P[∃t ≥ 1: Xt = j] = p > 0`
- `P[going to i from j] = 0`
- `f{ii} ≤ 1 - p`
1. `i` is recurrent  `=>  f{ii} = 1`
	- `X0 = i -> X1 = j`
	- `i` is accessible from `j  =>  ∃t: r_{ji}(t) = ε > 0`
	- the time to return to `i` is bounded
	

Df: Visits
----------
- `i ∈ S: V_i =` # of visits to `i = |{t: Xt = i}|`
- `Vi ∈ ℕ0 ∪ {∞}`
- `Vi` is a random variable defined using sequence `X0, X1, ...`


Df: Escape probability
----------------------
- `i ∈ S: 1 - f{ii}`


Th:
---
1. `i` is recurrent  `=>  P[Vi = ∞ | X0 = i] = 1   <=   f{ii} = 1`
2. `i` is transient  `=>  (Vi | X0 = i)  ~ Geom(1 - f{ii})`


Df: Steady state
----------------
- `π` is a distribution on `S (Σ{i ∈ |S|} πi, πi ≥ 0)`


Df: Stationary distribution
---------------------------
- `π` is a **stationary distribution** of a Markov chain with transition matrix `P` if `πP = π`
- `∀ j: πj = Σ{i ∈ S} πi Pij`


Ob: Stationary distribution
---------------------------
- `π^(0) = π   ∧   π` is stationary   `=>   ∀k: π^(k) = π`


Ex: Stationary distribution
---------------------------
1.
	+ two disconnected states, both loop with `P = 1`
	- `X0 = X1 = X2 = ...`
	- `π^(0) = π^(1) = ...`
	+ `∀p ∈ [0,1]: π = (p, 1-p)` is stationary
	+ `P = I_2` (id matrix)
2.
	+ two states with transitions between each other with `P = 1`
	- `X0 = X2 = X4 = ...`
	- `X1 = X3 = X5 = ...`
	- `X0 = 1 - X2`
	+ `π = (1/2, 1/2)` is stationary
	+ `P^{2k+1} =` reflected `I_2`
	+ `P^{2k} = I_2 ?`


Df: Periodic state
------------------
1. `s ∈ S` is **periodic**, `if ∃ 1 < Δ ∈ ℕ: P[Xt = s | X0 = s] > 0   =>   Δ | t`
2. a Markov chain is **periodic** if all states are **periodic**
3. otherwise, it is **aperiodic**


Th:
---
- `(Xt){t=0}^∞` is an irreducible, aperdiodic Markov chain with `|S| < ∞` (finite set of states)
- `=>  ∃π` stationary distribution
1. `∀j ∀i: lim{k -> ∞} r{ij}(k) = πj`
2. `π` is a unique solution to  `πP = π  and  πj = 1`   for `j = (1, ..., 1)`


We know
-------
- `Pj = j  =>   (P - I)j = 0`
- so `P - I` is a singleton   `=>   ∃ x` row vector: `x(P - I) = 0   =>   xP = x`


Applications
------------
1. given a Markov chain, what a stationary distribution
2. construct a Markov chain with a desirable `π`