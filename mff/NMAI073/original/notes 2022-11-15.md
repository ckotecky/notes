2022-11-15
lecture #6
----------



Nt:
---
- `f{Î˜|X}(ğ›|x) = fÎ˜(ğ›) * f{X|Î˜}(x|ğ›) / âˆ« (fÎ˜(ğ›') * f{X|Î˜}(x|ğ›') dğ›')`
- `f{Î˜|X}(ğ›|x) = fÎ˜(ğ›) * f{X|Î˜}(x|ğ›) / Î£ (fÎ˜(ğ›') * f{X|Î˜}(x|ğ›'))`

+ solved by numerical methods
	- sampling from distribution with PDF `fÎ˜` / PDF `pÎ˜`
	- MCMC (Markov chain Monte Carlo) method
		- Markov chain: created from a stationary distribution
		- Monte Carlo: randomized algorithm




CONDITIONAL EXPECTATION
=======================

- `ğ”¼[Y] = Î£{y âˆˆ Im(Y)} y * P[Y = y]`
- `ğ”¼[Y] = âˆ«{-âˆ, +âˆ} y * fY(y)`

+ `A âŠ† Î©, A âˆˆ ğ“™:`
- `ğ”¼[Y|A] = Î£ y P[Y = y | A]`
- `ğ”¼[Y|A] = âˆ« y f{Y|A}(y)`



Df: Conditional expectation
---------------------------
- `X,Y` random variables
- `x âˆˆ â„`
+ `g(x) := ğ”¼[Y | X = x]`
	* `g(x):â„ -> â„`
+ `ğ”¼[Y | X] = g(X)`

- `X:Î© -> g:â„ -> â„`


Ex: Conditional expectation
---------------------------
- Coin with probability of Heads equal to `X ~ U(0,1)`
- `Y =` # of H in n tosses
- `{Y | X = x} ~ Bin(n, x)`
- `ğ”¼[Y | X = x] = nx`
- `ğ”¼[Y | X] = nX`


Ob: Law of iterated expectation (LIE)
-------------------------------------
- `ğ”¼[ğ”¼[Y | X]] = ğ”¼[g(X)] =(LOTUS)= Î£{x âˆˆ Im(X)} g(x) * P[X = x] = Î£{x âˆˆ Im(X)} P[X = x] * ğ”¼[Y | X = x] =(Law of total ğ”¼)= ğ”¼[Y]`
	+ assuming X is discrete
- holds if `ğ”¼[Y] < âˆ`

- `ğ”¼[Y] = ğ”¼[ğ”¼[Y|X]] = ğ”¼[nX] = nğ”¼[X]= n/2`


Ex:
---
- stick of length l
- break the stick at a random point `X ~ U(0,l)`
- assuming `X = x`, we break the left part at point `Y ~ U(0,x)`
+ `ğ”¼[Y] = ğ”¼[ğ”¼[Y|X]] = ğ”¼[X/2] = ğ”¼[X]/2 = l/4`
	* `ğ”¼[Y|X] = g(X)`
	* `g(x) = ğ”¼[Y | X = x] ~ U(0,x)`


Ex:
---
| group |    score	 |  `|A|`  |  `{{Y}}`   |
|   `X`   | 	   `Y`     |       |          |
|-------|------------|-------|----------|
|   1   |10,15,20,17 |   4   | 	 175	|
|   2   |   5, 30    |   2   |   175    |
|  ...  |  100, 200  |   2   |   150	|
|   `k`   |    ...     |  ...  |			|

- set of students `|Î©| = 1`
- `Ax = {Ï‰ âˆˆ Î©: X(Ï‰) = x}`
- `nx = |Ax|`
- `ğ”¼[Y] = Î£{Ï‰ âˆˆ Î©} Y(Ï‰) * 1/n = Î£{x = 1, k} (Î£{Ï‰ âˆˆ Ax} Y(Ï‰) * 1/nx) * nx/n`
	+ `Î£{Ï‰ âˆˆ Ax} Y(Ï‰) * 1/nx = ğ”¼[Y | X = x]`
	+ `Î£{Ï‰ âˆˆ Ax} Y(Ï‰) * 1/nx * P[X = x]`
- `= Î£{x = 1, k} Î£{Ï‰ âˆˆ Ax} Y(Ï‰) * 1/nx * P[X = x]`
- `ğ”¼[Y]` estimate of `Y`
- `{{Y}} = ğ”¼[Y | X]` 														`{{Y}} = \hat{Y}`
	+ `{{Y}}:Î© -> â„`
	+ `X` is some observed data
	+ `Y` quantity of interest
	+ `{{Y}}` is called **estimator** (function)
- `{{{Y}}} `				 												`{{{Y}}} = \tilde{Y}`
	+ `{{{Y}}} = {{Y}} - Y`
	+ **error of estimation**
- `ğ”¼[{{{Y}}} | X] = ğ”¼[{{Y}} - Y | X] = ğ”¼[{{Y}} | X] = ğ”¼[Y | X]`
	+ `ğ”¼[{{Y}} | X] = ğ”¼[ğ”¼[Y|X] | X] = {{Y}} = ğ”¼[Y | X]`
	+ `ğ”¼[{{{Y}}}] = 0`
	+ bias of `{{Y}}` is 0 (by LIE)

+ `ğ”¼[{{{Y}}} * {{Y}}] =?= 0 = ğ”¼[{{{Y}}}] * ğ”¼[{{Y}}]`
	- `=> cov[{{{Y}}}, {{Y}}] = 0`
	- `ğ”¼[ğ”¼[{{{Y}}} * {{Y}} | X]] =!= ğ”¼[{{{Y}}} * ğ”¼[{{Y}} | X]] = ğ”¼[0] = 0`
	
+ `Y = {{Y}} - {{{Y}}}`
+ `var[Y] = var[{{Y}}] + var[{{{Y}}}] - 2cov[{{Y}}, {{{Y}}}]`
+ `{{Y}}, {{{Y}}}` are statistically independent - their covariance is 0
+ `var[{{{Y}}}] = ğ”¼[{{{Y}}}^2] =LIE= ğ”¼[ğ”¼[{{Y}}^2 | X]]`
+ `ğ”¼[{{{Y}}}^2 | X] = ğ”¼[(Y - {{Y}})^2 | X] = ğ”¼[(Y - ğ”¼[Y|X])^2 | X] = var[Y | X]` **conditional variance**
	* `var[Y | X] = h(X)`
	* `h(x) = var[Y | X = x]`
	* `var[Y] = ğ”¼[var[Y | X]] + var[ğ”¼[Y | X]]` **law of iterated variance /  Eve's rule** 
		- `var[Y | X]` = variance within the group
		- `var[ğ”¼[Y | X]]` = intergroup variance



LMS `<=>` conditional expectations
----------------------------------
- given random variable `Y`, what value of `y` minimizes `ğ”¼[Y - y]^2`
- `ğ”¼[Y - y]^2 = ğ”¼[Y^2] - 2yğ”¼[Y] + y^2 = f(y)`
- `f'(y) = -2ğ”¼[Y] + 2y = 0   =>   y = ğ”¼[Y]`

+ `âˆ€x`: find `y = y(x): ğ”¼[(Y - y(x))^2 | X = x]` is minimized
	- same calculation restricted to a smaller probability space  `=>  y(x) = ğ”¼[Y | X = x]`
	- our *best* estimator is `{{Y}} = ğ”¼[Y|X]`
		+ best in the LMS sense